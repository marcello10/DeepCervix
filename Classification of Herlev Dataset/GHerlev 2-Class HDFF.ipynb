{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib7Eqxu-M6ZF"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# data visualisation and manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        " \n",
        "#configure\n",
        "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
        "%matplotlib inline\n",
        "\n",
        "#model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#preprocess.\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#dl libraraies\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# specifically for cnn\n",
        "from tensorflow.keras.layers import Dropout, Flatten,Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        " \n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "\n",
        "# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\n",
        "import cv2                  \n",
        "import numpy as np  \n",
        "from tqdm import tqdm\n",
        "import os                   \n",
        "from random import shuffle  \n",
        "from zipfile import ZipFile\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeQuv3FhNxYF"
      },
      "outputs": [],
      "source": [
        "#Tensorboard Things\n",
        "\n",
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXE1gluFbDjh"
      },
      "outputs": [],
      "source": [
        "from dataset_division import *\n",
        "from dataset_aug import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "lDM-97EIVvtn",
        "outputId": "ea075d50-7941-40d9-85c8-482f8eebd914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instance of the class created\n",
            "Just testing that the method calling is workinglets go\n",
            "Dataset Division finished.\n",
            "Dataset Division finished.\n"
          ]
        }
      ],
      "source": [
        "path_dir= \"/content/smearbinary/herlev/\"\n",
        "output_dir = \"/content/herle2005Format\"\n",
        "datasetdiv1 = DatasetDivision(path_dir,output_dir)\n",
        "datasetdiv1.printnow(\"lets go\")\n",
        "datasetdiv1.divide_dataset(path_dir, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "xcZHAlbgoazF",
        "outputId": "da9f1708-a6f3-40ba-ceb8-9bdd3e375cb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instance of DataAugmentation_Extension class created\n",
            "HEY\n",
            "Instance of the DataAugmentation class created\n",
            "Directory exists\n",
            "['/content/herle2005Format/train/Normal/209566047-209566095-001.BMP', '/content/herle2005Format/train/Normal/209522641-209522674-001.BMP', '/content/herle2005Format/train/Normal/153958547-153958572-006.BMP', '/content/herle2005Format/train/Normal/209565864-209565911-001.BMP', '/content/herle2005Format/train/Normal/157183828-157183877-001.BMP', '/content/herle2005Format/train/Normal/209047526-209047762-001.BMP', '/content/herle2005Format/train/Normal/153956444-153956458-001.BMP', '/content/herle2005Format/train/Normal/157185781-157185814-001.BMP', '/content/herle2005Format/train/Normal/157185730-157185758-002.BMP', '/content/herle2005Format/train/Normal/157185433-157185479-003.BMP', '/content/herle2005Format/train/Normal/209565864-209565950-001.BMP', '/content/herle2005Format/train/Normal/157224297-157224336-001.BMP', '/content/herle2005Format/train/Normal/157181671-157181686-001.BMP', '/content/herle2005Format/train/Normal/157222534-157222579-001.BMP', '/content/herle2005Format/train/Normal/209522316-209522391-001.BMP', '/content/herle2005Format/train/Normal/209048086-209048278-001.BMP', '/content/herle2005Format/train/Normal/209566205-209566289-001.BMP', '/content/herle2005Format/train/Normal/157185433-157185508-005.BMP', '/content/herle2005Format/train/Normal/157185433-157185479-001.BMP', '/content/herle2005Format/train/Normal/209047342-209047400-001.BMP', '/content/herle2005Format/train/Normal/157223779-157224126-001.BMP', '/content/herle2005Format/train/Normal/157224412-157224429-001.BMP', '/content/herle2005Format/train/Normal/153956040-153956072-004.BMP', '/content/herle2005Format/train/Normal/209047342-209047478-001.BMP', '/content/herle2005Format/train/Normal/157223394-157223428-002.BMP', '/content/herle2005Format/train/Normal/157183828-157183887-001.BMP', '/content/herle2005Format/train/Normal/157224244-157224258-001.BMP', '/content/herle2005Format/train/Normal/157185133-157185143-001.BMP', '/content/herle2005Format/train/Normal/153958154-153958179-001.BMP', '/content/herle2005Format/train/Normal/153956040-153956072-003.BMP', '/content/herle2005Format/train/Normal/157185433-157185508-001.BMP', '/content/herle2005Format/train/Normal/157183412-157183656-001.BMP', '/content/herle2005Format/train/Normal/157222904-157223217-001.BMP', '/content/herle2005Format/train/Normal/209047526-209047626-001.BMP', '/content/herle2005Format/train/Normal/157268504-157268544-001.BMP', '/content/herle2005Format/train/Normal/157181146-157181197-003.BMP', '/content/herle2005Format/train/Normal/157181481-157181497-004.BMP', '/content/herle2005Format/train/Normal/209047881-209047928-001.BMP', '/content/herle2005Format/train/Normal/157223321-157223328-001.BMP', '/content/herle2005Format/train/Normal/153958154-153958168-003.BMP', '/content/herle2005Format/train/Normal/157185527-157185540-003.BMP', '/content/herle2005Format/train/Normal/209566205-209566247-001.BMP', '/content/herle2005Format/train/Normal/157224172-157224207-002.BMP', '/content/herle2005Format/train/Normal/209566047-209566125-001.BMP', '/content/herle2005Format/train/Normal/209566399-209566464-001.BMP', '/content/herle2005Format/train/Normal/157185433-157185479-007.BMP', '/content/herle2005Format/train/Normal/209566205-209566321-001.BMP', '/content/herle2005Format/train/Normal/157181146-157181197-001.BMP', '/content/herle2005Format/train/Normal/209565698-209565772-001.BMP', '/content/herle2005Format/train/Normal/157268342-157268401-001.BMP', '/content/herle2005Format/train/Normal/157185677-157185690-001.BMP', '/content/herle2005Format/train/Normal/158986920-158986928-001.BMP', '/content/herle2005Format/train/Normal/157222534-157222561-001.BMP', '/content/herle2005Format/train/Normal/157184850-157184891-001.BMP', '/content/herle2005Format/train/Normal/153955676-153955721-001.BMP', '/content/herle2005Format/train/Normal/157268587-157268617-001.BMP', '/content/herle2005Format/train/Normal/157181387-157181418-001.BMP', '/content/herle2005Format/train/Normal/157222534-157222607-001.BMP', '/content/herle2005Format/train/Normal/157183722-157183783-001.BMP', '/content/herle2005Format/train/Normal/153958547-153958572-009.BMP', '/content/herle2005Format/train/Normal/158987493-158987499-001.BMP', '/content/herle2005Format/train/Normal/157223735-157223766-001.BMP', '/content/herle2005Format/train/Normal/157223779-157224140-001.BMP', '/content/herle2005Format/train/Normal/157268504-157268534-001.BMP', '/content/herle2005Format/train/Normal/157181481-157181497-002.BMP', '/content/herle2005Format/train/Normal/157184013-157184031-001.BMP', '/content/herle2005Format/train/Normal/157267059-157267072-003.BMP', '/content/herle2005Format/train/Normal/153958154-153958179-002.BMP', '/content/herle2005Format/train/Normal/153958154-153958194-003.BMP', '/content/herle2005Format/train/Normal/157184850-157184920-002.BMP', '/content/herle2005Format/train/Normal/209522474-209522554-001.BMP', '/content/herle2005Format/train/Normal/157222904-157223196-001.BMP', '/content/herle2005Format/train/Normal/153958547-153958572-005.BMP', '/content/herle2005Format/train/Normal/153956040-153956058-006.BMP', '/content/herle2005Format/train/Normal/153958547-153958572-007.BMP', '/content/herle2005Format/train/Normal/157223321-157223341-001.BMP', '/content/herle2005Format/train/Normal/157267263-157267286-001.BMP', '/content/herle2005Format/train/Normal/153956040-153956072-001.BMP', '/content/herle2005Format/train/Normal/157222801-157222811-001.BMP', '/content/herle2005Format/train/Normal/209522474-209522522-001.BMP', '/content/herle2005Format/train/Normal/209566205-209566266-001.BMP', '/content/herle2005Format/train/Normal/209565409-209565466-001.BMP', '/content/herle2005Format/train/Normal/157224172-157224207-003.BMP', '/content/herle2005Format/train/Normal/158986766-158986776-002.BMP', '/content/herle2005Format/train/Normal/153958547-153958590-001.BMP', '/content/herle2005Format/train/Normal/157185433-157185508-004.BMP', '/content/herle2005Format/train/Normal/157222534-157223349-001.BMP', '/content/herle2005Format/train/Normal/157224172-157224207-001.BMP', '/content/herle2005Format/train/Normal/157185433-157185508-002.BMP', '/content/herle2005Format/train/Normal/157183828-157183840-001.BMP', '/content/herle2005Format/train/Normal/157185433-157185508-003.BMP', '/content/herle2005Format/train/Normal/157266930-157266947-001.BMP', '/content/herle2005Format/train/Normal/157181569-157181599-001.BMP', '/content/herle2005Format/train/Normal/157181671-157181697-001.BMP', '/content/herle2005Format/train/Normal/157224352-157224395-001.BMP', '/content/herle2005Format/train/Normal/157185054-157185079-001.BMP', '/content/herle2005Format/train/Normal/153958154-153958248-002.BMP', '/content/herle2005Format/train/Normal/209048086-209048239-001.BMP', '/content/herle2005Format/train/Normal/158986813-158986820-002.BMP', '/content/herle2005Format/train/Normal/157185433-157185479-005.BMP', '/content/herle2005Format/train/Normal/157222737-157222750-002.BMP', '/content/herle2005Format/train/Normal/209565698-209565729-001.BMP', '/content/herle2005Format/train/Normal/157224297-157224320-001.BMP', '/content/herle2005Format/train/Normal/157227058-157227087-001.BMP', '/content/herle2005Format/train/Normal/153958154-153958211-001.BMP', '/content/herle2005Format/train/Normal/157183412-157183638-001.BMP', '/content/herle2005Format/train/Normal/157268242-157268296-001.BMP', '/content/herle2005Format/train/Normal/153956444-153956458-003.BMP', '/content/herle2005Format/train/Normal/157183412-157183614-001.BMP', '/content/herle2005Format/train/Normal/157222534-157223364-001.BMP', '/content/herle2005Format/train/Normal/157268342-157268376-001.BMP', '/content/herle2005Format/train/Normal/157224458-157224464-001.BMP', '/content/herle2005Format/train/Normal/153958547-153958572-001.BMP', '/content/herle2005Format/train/Normal/153958547-153958572-003.BMP', '/content/herle2005Format/train/Normal/153956040-153956058-001.BMP', '/content/herle2005Format/train/Normal/157181146-157181197-002.BMP', '/content/herle2005Format/train/Normal/157222647-157222660-001.BMP', '/content/herle2005Format/train/Normal/209307421-209307597-001.BMP', '/content/herle2005Format/train/Normal/157181525-157181540-001.BMP', '/content/herle2005Format/train/Normal/157185527-157185540-002.BMP', '/content/herle2005Format/train/Normal/157223394-157223406-001.BMP', '/content/herle2005Format/train/Normal/157223394-157223428-001.BMP', '/content/herle2005Format/train/Normal/157224172-157224179-001.BMP', '/content/herle2005Format/train/Normal/157181481-157181497-003.BMP', '/content/herle2005Format/train/Normal/157183332-157183346-001.BMP', '/content/herle2005Format/train/Normal/157184112-157184128-001.BMP', '/content/herle2005Format/train/Normal/158986766-158986776-001.BMP', '/content/herle2005Format/train/Normal/209566399-209566517-001.BMP', '/content/herle2005Format/train/Normal/157185208-157185238-001.BMP', '/content/herle2005Format/train/Normal/153956040-153956072-002.BMP', '/content/herle2005Format/train/Normal/209307421-209307561-001.BMP', '/content/herle2005Format/train/Normal/157183964-157183980-001.BMP', '/content/herle2005Format/train/Normal/157184112-157184120-001.BMP', '/content/herle2005Format/train/Normal/157227461-157227503-002.BMP', '/content/herle2005Format/train/Normal/157183332-157183388-001.BMP', '/content/herle2005Format/train/Normal/157267059-157267072-004.BMP', '/content/herle2005Format/train/Normal/209565409-209565600-001.BMP', '/content/herle2005Format/train/Normal/153956444-153956458-002.BMP', '/content/herle2005Format/train/Normal/153956040-153956058-004.BMP', '/content/herle2005Format/train/Normal/157184850-157184976-001.BMP', '/content/herle2005Format/train/Normal/157185781-157185793-003.BMP', '/content/herle2005Format/train/Normal/157185613-157185627-001.BMP', '/content/herle2005Format/train/Normal/157185781-157185793-002.BMP', '/content/herle2005Format/train/Normal/153958154-153958194-002.BMP']\n",
            "['/content/herle2005Format/train/Abnormal/149061221-149061289-001.BMP', '/content/herle2005Format/train/Abnormal/148503568-148503580-001.BMP', '/content/herle2005Format/train/Abnormal/149062593-149062608-001.BMP', '/content/herle2005Format/train/Abnormal/149181806-149181819-001.BMP', '/content/herle2005Format/train/Abnormal/149315671-149315749-002.BMP', '/content/herle2005Format/train/Abnormal/153268036-153268083-001.BMP', '/content/herle2005Format/train/Abnormal/148848523-148848559-002.BMP', '/content/herle2005Format/train/Abnormal/149182550-149182571-004.BMP', '/content/herle2005Format/train/Abnormal/153831471-153831479-001.BMP', '/content/herle2005Format/train/Abnormal/153701009-153701019-002.BMP', '/content/herle2005Format/train/Abnormal/149058170-149058202-002.BMP', '/content/herle2005Format/train/Abnormal/149140081-149140096-002.BMP', '/content/herle2005Format/train/Abnormal/149317002-149317018-001.BMP', '/content/herle2005Format/train/Abnormal/149314679-149314698-003.BMP', '/content/herle2005Format/train/Abnormal/149147060-149147075-001.BMP', '/content/herle2005Format/train/Abnormal/153315615-153315629-003.BMP', '/content/herle2005Format/train/Abnormal/149317204-149317230-003.BMP', '/content/herle2005Format/train/Abnormal/149057756-149057766-001.BMP', '/content/herle2005Format/train/Abnormal/153659229-153659256-001.BMP', '/content/herle2005Format/train/Abnormal/149059215-149059228-002.BMP', '/content/herle2005Format/train/Abnormal/153828952-153828980-001.BMP', '/content/herle2005Format/train/Abnormal/149315229-149315310-001.BMP', '/content/herle2005Format/train/Abnormal/148842055-148842064-001.BMP', '/content/herle2005Format/train/Abnormal/153701139-153701158-003.BMP', '/content/herle2005Format/train/Abnormal/149358108-149358125-001.BMP', '/content/herle2005Format/train/Abnormal/149148669-149148707-002.BMP', '/content/herle2005Format/train/Abnormal/149788987-149788996-003.BMP', '/content/herle2005Format/train/Abnormal/153659229-153659256-002.BMP', '/content/herle2005Format/train/Abnormal/153700207-153700215-001.BMP', '/content/herle2005Format/train/Abnormal/148503400-148503432-001.BMP', '/content/herle2005Format/train/Abnormal/149182550-149182608-003.BMP', '/content/herle2005Format/train/Abnormal/153915634-153915665-005.BMP', '/content/herle2005Format/train/Abnormal/149316117-149316122-004.BMP', '/content/herle2005Format/train/Abnormal/153826963-153826976-002.BMP', '/content/herle2005Format/train/Abnormal/153656862-153656873-001.BMP', '/content/herle2005Format/train/Abnormal/153276386-153276405-003.BMP', '/content/herle2005Format/train/Abnormal/153314466-153314473-001.BMP', '/content/herle2005Format/train/Abnormal/149054277-149054304-001.BMP', '/content/herle2005Format/train/Abnormal/153701949-153701964-001.BMP', '/content/herle2005Format/train/Abnormal/153830680-153830827-002.BMP', '/content/herle2005Format/train/Abnormal/149148124-149148181-003.BMP', '/content/herle2005Format/train/Abnormal/149105131-149105205-002.BMP', '/content/herle2005Format/train/Abnormal/153829664-153829672-001.BMP', '/content/herle2005Format/train/Abnormal/148495842-148495863-001.BMP', '/content/herle2005Format/train/Abnormal/148499383-148499452-001.BMP', '/content/herle2005Format/train/Abnormal/204870858-204870872-002.BMP', '/content/herle2005Format/train/Abnormal/149099680-149099714-001.BMP', '/content/herle2005Format/train/Abnormal/149056321-149056360-003.BMP', '/content/herle2005Format/train/Abnormal/149186957-149186968-002.BMP', '/content/herle2005Format/train/Abnormal/149058262-149058288-004.BMP', '/content/herle2005Format/train/Abnormal/153314956-153314985-001.BMP', '/content/herle2005Format/train/Abnormal/153700207-153700224-001.BMP', '/content/herle2005Format/train/Abnormal/153313074-153313079-001.BMP', '/content/herle2005Format/train/Abnormal/153275831-153275844-001.BMP', '/content/herle2005Format/train/Abnormal/148881729-148881744-001.BMP', '/content/herle2005Format/train/Abnormal/149182657-149182713-002.BMP', '/content/herle2005Format/train/Abnormal/153314857-153314882-002.BMP', '/content/herle2005Format/train/Abnormal/149058262-149058288-002.BMP', '/content/herle2005Format/train/Abnormal/149062753-149062761-001.BMP', '/content/herle2005Format/train/Abnormal/148882535-148882616-001.BMP', '/content/herle2005Format/train/Abnormal/153657327-153657363-001.BMP', '/content/herle2005Format/train/Abnormal/153697342-153697375-002.BMP', '/content/herle2005Format/train/Abnormal/149014631-149014646-003.BMP', '/content/herle2005Format/train/Abnormal/149014631-149014654-001.BMP', '/content/herle2005Format/train/Abnormal/148881870-148882178-002.BMP', '/content/herle2005Format/train/Abnormal/149056785-149056797-004.BMP', '/content/herle2005Format/train/Abnormal/153655016-153655039-005.BMP', '/content/herle2005Format/train/Abnormal/149101437-149101456-001.BMP', '/content/herle2005Format/train/Abnormal/148719308-148719348-002.BMP', '/content/herle2005Format/train/Abnormal/153659229-153659243-003.BMP', '/content/herle2005Format/train/Abnormal/149099096-149099104-001.BMP', '/content/herle2005Format/train/Abnormal/153657698-153657708-001.BMP', '/content/herle2005Format/train/Abnormal/149056545-149056555-002.BMP', '/content/herle2005Format/train/Abnormal/153828952-153829005-001.BMP', '/content/herle2005Format/train/Abnormal/149190861-149190868-001.BMP', '/content/herle2005Format/train/Abnormal/149105289-149105311-003.BMP', '/content/herle2005Format/train/Abnormal/149102442-149102460-002.BMP', '/content/herle2005Format/train/Abnormal/153831352-153831372-002.BMP', '/content/herle2005Format/train/Abnormal/149101620-149101650-002.BMP', '/content/herle2005Format/train/Abnormal/149053945-149053976-001.BMP', '/content/herle2005Format/train/Abnormal/149098972-149099015-001.BMP', '/content/herle2005Format/train/Abnormal/149099276-149099290-001.BMP', '/content/herle2005Format/train/Abnormal/148503664-148503685-002.BMP', '/content/herle2005Format/train/Abnormal/149014631-149014654-003.BMP', '/content/herle2005Format/train/Abnormal/149097594-149097661-001.BMP', '/content/herle2005Format/train/Abnormal/148719308-148719357-001.BMP', '/content/herle2005Format/train/Abnormal/149316852-149316872-001.BMP', '/content/herle2005Format/train/Abnormal/149053945-149053969-001.BMP', '/content/herle2005Format/train/Abnormal/149317002-149317010-002.BMP', '/content/herle2005Format/train/Abnormal/153827595-153827657-001.BMP', '/content/herle2005Format/train/Abnormal/153915634-153915665-001.BMP', '/content/herle2005Format/train/Abnormal/148839765-148839773-001.BMP', '/content/herle2005Format/train/Abnormal/153828877-153828902-002.BMP', '/content/herle2005Format/train/Abnormal/153828877-153828890-001.BMP', '/content/herle2005Format/train/Abnormal/149182657-149182667-002.BMP', '/content/herle2005Format/train/Abnormal/149060626-149060638-002.BMP', '/content/herle2005Format/train/Abnormal/149056785-149056813-002.BMP', '/content/herle2005Format/train/Abnormal/149315671-149315740-004.BMP', '/content/herle2005Format/train/Abnormal/149057812-149057847-006.BMP', '/content/herle2005Format/train/Abnormal/204870951-204870961-002.BMP', '/content/herle2005Format/train/Abnormal/149185698-149185721-001.BMP', '/content/herle2005Format/train/Abnormal/149181904-149182044-001.BMP', '/content/herle2005Format/train/Abnormal/149014929-149015008-001.BMP', '/content/herle2005Format/train/Abnormal/153654325-153654360-001.BMP', '/content/herle2005Format/train/Abnormal/149097324-149097388-001.BMP', '/content/herle2005Format/train/Abnormal/153655016-153655039-003.BMP', '/content/herle2005Format/train/Abnormal/153831027-153831045-003.BMP', '/content/herle2005Format/train/Abnormal/149148124-149148181-001.BMP', '/content/herle2005Format/train/Abnormal/149147848-149147864-002.BMP', '/content/herle2005Format/train/Abnormal/149185497-149185527-001.BMP', '/content/herle2005Format/train/Abnormal/153915726-153915736-001.BMP', '/content/herle2005Format/train/Abnormal/149100006-149100028-001.BMP', '/content/herle2005Format/train/Abnormal/149317114-149317152-002.BMP', '/content/herle2005Format/train/Abnormal/204870892-204870902-001.BMP', '/content/herle2005Format/train/Abnormal/149099398-149099421-001.BMP', '/content/herle2005Format/train/Abnormal/149185604-149185645-005.BMP', '/content/herle2005Format/train/Abnormal/149185788-149185824-001.BMP', '/content/herle2005Format/train/Abnormal/149058262-149058309-001.BMP', '/content/herle2005Format/train/Abnormal/149182657-149182667-001.BMP', '/content/herle2005Format/train/Abnormal/148499383-148499452-002.BMP', '/content/herle2005Format/train/Abnormal/149187049-149187100-002.BMP', '/content/herle2005Format/train/Abnormal/153702037-153702060-001.BMP', '/content/herle2005Format/train/Abnormal/153831471-153831486-004.BMP', '/content/herle2005Format/train/Abnormal/153702037-153702051-002.BMP', '/content/herle2005Format/train/Abnormal/149054642-149054677-003.BMP', '/content/herle2005Format/train/Abnormal/149056321-149056343-003.BMP', '/content/herle2005Format/train/Abnormal/149105289-149105311-004.BMP', '/content/herle2005Format/train/Abnormal/153829700-153829705-001.BMP', '/content/herle2005Format/train/Abnormal/149788716-149788727-002.BMP', '/content/herle2005Format/train/Abnormal/149185604-149185645-002.BMP', '/content/herle2005Format/train/Abnormal/149013033-149013072-001.BMP', '/content/herle2005Format/train/Abnormal/149105131-149105260-002.BMP', '/content/herle2005Format/train/Abnormal/149056410-149056458-005.BMP', '/content/herle2005Format/train/Abnormal/148881870-148881960-002.BMP', '/content/herle2005Format/train/Abnormal/153275893-153275939-003.BMP', '/content/herle2005Format/train/Abnormal/149185698-149185709-002.BMP', '/content/herle2005Format/train/Abnormal/149181904-149182044-003.BMP', '/content/herle2005Format/train/Abnormal/153354858-153354901-002.BMP', '/content/herle2005Format/train/Abnormal/149060932-149060940-001.BMP', '/content/herle2005Format/train/Abnormal/149061548-149061568-003.BMP', '/content/herle2005Format/train/Abnormal/149095913-149095926-001.BMP', '/content/herle2005Format/train/Abnormal/153831471-153831486-003.BMP', '/content/herle2005Format/train/Abnormal/153826963-153826989-001.BMP', '/content/herle2005Format/train/Abnormal/149147848-149147864-001.BMP', '/content/herle2005Format/train/Abnormal/153657257-153657289-002.BMP', '/content/herle2005Format/train/Abnormal/148718455-148718461-001.BMP', '/content/herle2005Format/train/Abnormal/149788716-149788727-001.BMP', '/content/herle2005Format/train/Abnormal/149314679-149314698-002.BMP', '/content/herle2005Format/train/Abnormal/149058262-149058288-005.BMP', '/content/herle2005Format/train/Abnormal/153828877-153828890-002.BMP', '/content/herle2005Format/train/Abnormal/148882307-148882323-001.BMP', '/content/herle2005Format/train/Abnormal/149315372-149315390-001.BMP', '/content/herle2005Format/train/Abnormal/153655016-153655039-004.BMP', '/content/herle2005Format/train/Abnormal/148884702-148884710-002.BMP', '/content/herle2005Format/train/Abnormal/149096927-149096943-002.BMP', '/content/herle2005Format/train/Abnormal/149357956-149358043-001.BMP', '/content/herle2005Format/train/Abnormal/149316426-149316462-001.BMP', '/content/herle2005Format/train/Abnormal/149181904-149182044-002.BMP', '/content/herle2005Format/train/Abnormal/149185850-149185864-001.BMP', '/content/herle2005Format/train/Abnormal/153829745-153829763-001.BMP', '/content/herle2005Format/train/Abnormal/149185604-149185616-001.BMP', '/content/herle2005Format/train/Abnormal/149316117-149316131-001.BMP', '/content/herle2005Format/train/Abnormal/153276386-153276405-002.BMP', '/content/herle2005Format/train/Abnormal/153831027-153831036-001.BMP', '/content/herle2005Format/train/Abnormal/148886869-148886897-001.BMP', '/content/herle2005Format/train/Abnormal/153826597-153826619-001.BMP', '/content/herle2005Format/train/Abnormal/153654325-153654360-003.BMP', '/content/herle2005Format/train/Abnormal/149315229-149315291-002.BMP', '/content/herle2005Format/train/Abnormal/153701009-153701019-001.BMP', '/content/herle2005Format/train/Abnormal/149182657-149182681-002.BMP', '/content/herle2005Format/train/Abnormal/153830680-153830827-001.BMP', '/content/herle2005Format/train/Abnormal/149183509-149183519-001.BMP', '/content/herle2005Format/train/Abnormal/153827595-153827669-001.BMP', '/content/herle2005Format/train/Abnormal/149054526-149054540-001.BMP', '/content/herle2005Format/train/Abnormal/153916114-153916167-002.BMP', '/content/herle2005Format/train/Abnormal/149105131-149105155-002.BMP', '/content/herle2005Format/train/Abnormal/153314759-153314767-003.BMP', '/content/herle2005Format/train/Abnormal/148503071-148503092-002.BMP', '/content/herle2005Format/train/Abnormal/149102510-149102519-001.BMP', '/content/herle2005Format/train/Abnormal/149148124-149148168-001.BMP', '/content/herle2005Format/train/Abnormal/149014631-149014654-002.BMP', '/content/herle2005Format/train/Abnormal/153915432-153915441-002.BMP', '/content/herle2005Format/train/Abnormal/149185405-149185423-001.BMP', '/content/herle2005Format/train/Abnormal/153828952-153829000-001.BMP', '/content/herle2005Format/train/Abnormal/149315229-149315249-002.BMP', '/content/herle2005Format/train/Abnormal/149105289-149105311-001.BMP', '/content/herle2005Format/train/Abnormal/149056933-149056945-002.BMP', '/content/herle2005Format/train/Abnormal/149185698-149185721-002.BMP', '/content/herle2005Format/train/Abnormal/149014929-149014984-001.BMP', '/content/herle2005Format/train/Abnormal/149317114-149317152-001.BMP', '/content/herle2005Format/train/Abnormal/153828952-153829000-003.BMP', '/content/herle2005Format/train/Abnormal/153828952-153829009-002.BMP', '/content/herle2005Format/train/Abnormal/149185698-149185744-001.BMP', '/content/herle2005Format/train/Abnormal/149182550-149182608-004.BMP', '/content/herle2005Format/train/Abnormal/153698259-153698268-001.BMP', '/content/herle2005Format/train/Abnormal/149058881-149058910-001.BMP', '/content/herle2005Format/train/Abnormal/149788716-149788727-003.BMP', '/content/herle2005Format/train/Abnormal/149061548-149061568-004.BMP', '/content/herle2005Format/train/Abnormal/149058262-149058272-003.BMP', '/content/herle2005Format/train/Abnormal/149314453-149314507-001.BMP', '/content/herle2005Format/train/Abnormal/149181904-149181951-001.BMP', '/content/herle2005Format/train/Abnormal/153275893-153275939-001.BMP', '/content/herle2005Format/train/Abnormal/153701139-153701158-004.BMP', '/content/herle2005Format/train/Abnormal/149096854-149096870-001.BMP', '/content/herle2005Format/train/Abnormal/149314679-149314698-001.BMP', '/content/herle2005Format/train/Abnormal/149102510-149102527-002.BMP', '/content/herle2005Format/train/Abnormal/149056410-149056423-001.BMP', '/content/herle2005Format/train/Abnormal/153702037-153702051-001.BMP', '/content/herle2005Format/train/Abnormal/153831471-153831486-002.BMP', '/content/herle2005Format/train/Abnormal/148882535-148882616-002.BMP', '/content/herle2005Format/train/Abnormal/148503664-148503685-001.BMP', '/content/herle2005Format/train/Abnormal/149058170-149058202-001.BMP', '/content/herle2005Format/train/Abnormal/149185698-149185721-003.BMP', '/content/herle2005Format/train/Abnormal/149097324-149097352-001.BMP', '/content/herle2005Format/train/Abnormal/149097594-149097637-001.BMP', '/content/herle2005Format/train/Abnormal/148883996-148884017-001.BMP', '/content/herle2005Format/train/Abnormal/153831352-153831372-001.BMP', '/content/herle2005Format/train/Abnormal/149181904-149181927-001.BMP', '/content/herle2005Format/train/Abnormal/149057164-149057197-001.BMP', '/content/herle2005Format/train/Abnormal/149182125-149182135-001.BMP', '/content/herle2005Format/train/Abnormal/149788987-149789006-001.BMP', '/content/herle2005Format/train/Abnormal/148497788-148497816-002.BMP', '/content/herle2005Format/train/Abnormal/148497551-148497625-001.BMP', '/content/herle2005Format/train/Abnormal/153827595-153827604-004.BMP', '/content/herle2005Format/train/Abnormal/149056410-149056444-003.BMP', '/content/herle2005Format/train/Abnormal/153831352-153831372-004.BMP', '/content/herle2005Format/train/Abnormal/149096505-149096614-003.BMP', '/content/herle2005Format/train/Abnormal/149058262-149058288-001.BMP', '/content/herle2005Format/train/Abnormal/149315671-149315731-001.BMP', '/content/herle2005Format/train/Abnormal/148495553-148495585-001.BMP', '/content/herle2005Format/train/Abnormal/149098972-149098988-001.BMP', '/content/herle2005Format/train/Abnormal/149014929-149015008-002.BMP', '/content/herle2005Format/train/Abnormal/149140849-149140856-001.BMP', '/content/herle2005Format/train/Abnormal/148499383-148499474-001.BMP', '/content/herle2005Format/train/Abnormal/149014631-149014646-004.BMP', '/content/herle2005Format/train/Abnormal/153697342-153697375-003.BMP', '/content/herle2005Format/train/Abnormal/149143370-149143378-002.BMP', '/content/herle2005Format/train/Abnormal/149101894-149101918-001.BMP', '/content/herle2005Format/train/Abnormal/153314466-153314473-003.BMP', '/content/herle2005Format/train/Abnormal/153827595-153827664-001.BMP', '/content/herle2005Format/train/Abnormal/149100006-149100018-001.BMP', '/content/herle2005Format/train/Abnormal/149014929-149015022-002.BMP', '/content/herle2005Format/train/Abnormal/149182657-149182667-003.BMP', '/content/herle2005Format/train/Abnormal/148499815-148500094-001.BMP', '/content/herle2005Format/train/Abnormal/148881675-148881704-001.BMP', '/content/herle2005Format/train/Abnormal/153657257-153657289-001.BMP', '/content/herle2005Format/train/Abnormal/153827595-153827611-002.BMP', '/content/herle2005Format/train/Abnormal/149096505-149096614-002.BMP', '/content/herle2005Format/train/Abnormal/149146635-149146651-003.BMP', '/content/herle2005Format/train/Abnormal/149105289-149105311-002.BMP', '/content/herle2005Format/train/Abnormal/149316754-149316779-002.BMP', '/content/herle2005Format/train/Abnormal/149056933-149056982-003.BMP', '/content/herle2005Format/train/Abnormal/149056410-149056423-004.BMP', '/content/herle2005Format/train/Abnormal/149057812-149057825-001.BMP', '/content/herle2005Format/train/Abnormal/149181904-149181951-002.BMP', '/content/herle2005Format/train/Abnormal/149056410-149056458-004.BMP', '/content/herle2005Format/train/Abnormal/148499383-148499424-002.BMP', '/content/herle2005Format/train/Abnormal/149060932-149060940-002.BMP', '/content/herle2005Format/train/Abnormal/153827595-153827657-002.BMP', '/content/herle2005Format/train/Abnormal/149057812-149057847-004.BMP', '/content/herle2005Format/train/Abnormal/149147060-149147075-002.BMP', '/content/herle2005Format/train/Abnormal/149105003-149105050-001.BMP', '/content/herle2005Format/train/Abnormal/153314956-153314996-001.BMP', '/content/herle2005Format/train/Abnormal/149182657-149182713-001.BMP', '/content/herle2005Format/train/Abnormal/149015814-149015831-001.BMP', '/content/herle2005Format/train/Abnormal/149056785-149056797-003.BMP', '/content/herle2005Format/train/Abnormal/149061548-149061568-002.BMP', '/content/herle2005Format/train/Abnormal/149182657-149182681-001.BMP', '/content/herle2005Format/train/Abnormal/149148669-149148707-001.BMP', '/content/herle2005Format/train/Abnormal/153916114-153916167-001.BMP', '/content/herle2005Format/train/Abnormal/148848523-148848559-004.BMP', '/content/herle2005Format/train/Abnormal/149143370-149143388-003.BMP', '/content/herle2005Format/train/Abnormal/149101437-149101467-001.BMP', '/content/herle2005Format/train/Abnormal/149314881-149314903-001.BMP', '/content/herle2005Format/train/Abnormal/149314453-149314507-003.BMP', '/content/herle2005Format/train/Abnormal/149057812-149057847-005.BMP', '/content/herle2005Format/train/Abnormal/149056410-149056458-001.BMP', '/content/herle2005Format/train/Abnormal/149357849-149357874-001.BMP', '/content/herle2005Format/train/Abnormal/153826963-153826982-002.BMP', '/content/herle2005Format/train/Abnormal/148883900-148883907-001.BMP', '/content/herle2005Format/train/Abnormal/149182550-149182571-002.BMP', '/content/herle2005Format/train/Abnormal/149014929-149014994-001.BMP', '/content/herle2005Format/train/Abnormal/149105131-149105205-001.BMP', '/content/herle2005Format/train/Abnormal/149182355-149182396-001.BMP', '/content/herle2005Format/train/Abnormal/149057261-149057272-002.BMP', '/content/herle2005Format/train/Abnormal/153314857-153314909-002.BMP', '/content/herle2005Format/train/Abnormal/153657599-153657633-001.BMP', '/content/herle2005Format/train/Abnormal/153916001-153916020-003.BMP', '/content/herle2005Format/train/Abnormal/148503400-148503415-003.BMP', '/content/herle2005Format/train/Abnormal/149057812-149057825-003.BMP', '/content/herle2005Format/train/Abnormal/149056785-149056797-001.BMP', '/content/herle2005Format/train/Abnormal/149105131-149105155-004.BMP', '/content/herle2005Format/train/Abnormal/149143469-149143497-001.BMP', '/content/herle2005Format/train/Abnormal/149100006-149100028-002.BMP', '/content/herle2005Format/train/Abnormal/148719308-148719348-004.BMP', '/content/herle2005Format/train/Abnormal/149105003-149105050-002.BMP', '/content/herle2005Format/train/Abnormal/148881870-148882178-001.BMP', '/content/herle2005Format/train/Abnormal/153655593-153655608-001.BMP', '/content/herle2005Format/train/Abnormal/153657121-153657160-002.BMP', '/content/herle2005Format/train/Abnormal/149357849-149357857-003.BMP', '/content/herle2005Format/train/Abnormal/204870926-204870933-001.BMP', '/content/herle2005Format/train/Abnormal/149102510-149102519-002.BMP', '/content/herle2005Format/train/Abnormal/149357849-149357867-001.BMP', '/content/herle2005Format/train/Abnormal/149182657-149182698-002.BMP', '/content/herle2005Format/train/Abnormal/149146837-149146854-001.BMP', '/content/herle2005Format/train/Abnormal/149146886-149146936-002.BMP', '/content/herle2005Format/train/Abnormal/149054642-149054724-001.BMP', '/content/herle2005Format/train/Abnormal/149014631-149014646-002.BMP', '/content/herle2005Format/train/Abnormal/149057261-149057272-001.BMP', '/content/herle2005Format/train/Abnormal/149056873-149056884-002.BMP', '/content/herle2005Format/train/Abnormal/149101894-149101930-003.BMP', '/content/herle2005Format/train/Abnormal/149105131-149105260-001.BMP', '/content/herle2005Format/train/Abnormal/148498683-148498703-001.BMP', '/content/herle2005Format/train/Abnormal/149182657-149182713-003.BMP', '/content/herle2005Format/train/Abnormal/149185604-149185657-002.BMP', '/content/herle2005Format/train/Abnormal/149059215-149059228-001.BMP', '/content/herle2005Format/train/Abnormal/148503664-148503675-002.BMP', '/content/herle2005Format/train/Abnormal/149316941-149316952-001.BMP', '/content/herle2005Format/train/Abnormal/148881870-148882187-001.BMP', '/content/herle2005Format/train/Abnormal/153916114-153916150-001.BMP', '/content/herle2005Format/train/Abnormal/149056785-149056813-006.BMP', '/content/herle2005Format/train/Abnormal/149147949-149147960-002.BMP', '/content/herle2005Format/train/Abnormal/149053423-149053447-001.BMP', '/content/herle2005Format/train/Abnormal/149316754-149316795-002.BMP', '/content/herle2005Format/train/Abnormal/149142457-149142465-001.BMP', '/content/herle2005Format/train/Abnormal/149140169-149140188-001.BMP', '/content/herle2005Format/train/Abnormal/149096927-149096943-001.BMP', '/content/herle2005Format/train/Abnormal/149102510-149102527-001.BMP', '/content/herle2005Format/train/Abnormal/148503400-148503424-001.BMP', '/content/herle2005Format/train/Abnormal/149057164-149057197-002.BMP', '/content/herle2005Format/train/Abnormal/153915634-153915665-007.BMP', '/content/herle2005Format/train/Abnormal/153276386-153276414-001.BMP', '/content/herle2005Format/train/Abnormal/149102510-149102527-003.BMP', '/content/herle2005Format/train/Abnormal/149056321-149056360-002.BMP', '/content/herle2005Format/train/Abnormal/149185604-149185645-003.BMP', '/content/herle2005Format/train/Abnormal/153276386-153276405-001.BMP', '/content/herle2005Format/train/Abnormal/149185604-149185629-001.BMP', '/content/herle2005Format/train/Abnormal/153659229-153659243-001.BMP', '/content/herle2005Format/train/Abnormal/149098972-149099015-002.BMP', '/content/herle2005Format/train/Abnormal/153828952-153829005-002.BMP', '/content/herle2005Format/train/Abnormal/148503664-148503675-001.BMP', '/content/herle2005Format/train/Abnormal/153827595-153827611-001.BMP', '/content/herle2005Format/train/Abnormal/153655016-153655039-001.BMP', '/content/herle2005Format/train/Abnormal/153266866-153266917-001.BMP', '/content/herle2005Format/train/Abnormal/148710162-148710195-002.BMP', '/content/herle2005Format/train/Abnormal/149096505-149096567-001.BMP', '/content/herle2005Format/train/Abnormal/149357849-149357867-002.BMP', '/content/herle2005Format/train/Abnormal/149053341-149053350-002.BMP', '/content/herle2005Format/train/Abnormal/148499274-148499302-001.BMP', '/content/herle2005Format/train/Abnormal/149315229-149315291-003.BMP', '/content/herle2005Format/train/Abnormal/153826963-153826976-001.BMP', '/content/herle2005Format/train/Abnormal/149182550-149182608-005.BMP', '/content/herle2005Format/train/Abnormal/149105131-149105155-003.BMP', '/content/herle2005Format/train/Abnormal/149185698-149185721-004.BMP', '/content/herle2005Format/train/Abnormal/149143370-149143388-001.BMP', '/content/herle2005Format/train/Abnormal/149058170-149058218-003.BMP', '/content/herle2005Format/train/Abnormal/148495885-148495896-001.BMP', '/content/herle2005Format/train/Abnormal/149147060-149147075-003.BMP', '/content/herle2005Format/train/Abnormal/149317204-149317230-002.BMP', '/content/herle2005Format/train/Abnormal/153916114-153916129-002.BMP', '/content/herle2005Format/train/Abnormal/149054642-149054677-002.BMP', '/content/herle2005Format/train/Abnormal/153314857-153314882-001.BMP', '/content/herle2005Format/train/Abnormal/149061666-149061726-003.BMP', '/content/herle2005Format/train/Abnormal/153829745-153829754-001.BMP', '/content/herle2005Format/train/Abnormal/149101894-149101930-001.BMP', '/content/herle2005Format/train/Abnormal/149056321-149056343-001.BMP', '/content/herle2005Format/train/Abnormal/153697342-153697366-001.BMP', '/content/herle2005Format/train/Abnormal/149054277-149054304-002.BMP', '/content/herle2005Format/train/Abnormal/153659229-153659264-001.BMP', '/content/herle2005Format/train/Abnormal/153654869-153654880-001.BMP', '/content/herle2005Format/train/Abnormal/153655593-153655600-002.BMP', '/content/herle2005Format/train/Abnormal/149056410-149056423-002.BMP', '/content/herle2005Format/train/Abnormal/153659229-153659256-003.BMP', '/content/herle2005Format/train/Abnormal/153266866-153266917-002.BMP', '/content/herle2005Format/train/Abnormal/149316941-149316961-002.BMP', '/content/herle2005Format/train/Abnormal/153698259-153698268-002.BMP', '/content/herle2005Format/train/Abnormal/149148669-149148707-003.BMP', '/content/herle2005Format/train/Abnormal/153656957-153656964-001.BMP', '/content/herle2005Format/train/Abnormal/149788987-149788996-001.BMP', '/content/herle2005Format/train/Abnormal/153915634-153915665-006.BMP', '/content/herle2005Format/train/Abnormal/153702037-153702051-003.BMP', '/content/herle2005Format/train/Abnormal/153829664-153829678-001.BMP', '/content/herle2005Format/train/Abnormal/149101894-149101930-002.BMP', '/content/herle2005Format/train/Abnormal/149182125-149182135-003.BMP', '/content/herle2005Format/train/Abnormal/153314857-153314909-001.BMP', '/content/herle2005Format/train/Abnormal/153826963-153826982-003.BMP', '/content/herle2005Format/train/Abnormal/153829063-153829073-001.BMP', '/content/herle2005Format/train/Abnormal/149187049-149187073-001.BMP', '/content/herle2005Format/train/Abnormal/149182550-149182571-003.BMP', '/content/herle2005Format/train/Abnormal/149315775-149315790-003.BMP', '/content/herle2005Format/train/Abnormal/149315671-149315731-002.BMP', '/content/herle2005Format/train/Abnormal/149316117-149316122-003.BMP', '/content/herle2005Format/train/Abnormal/148503209-148503231-001.BMP', '/content/herle2005Format/train/Abnormal/149140536-149140551-001.BMP', '/content/herle2005Format/train/Abnormal/153831027-153831045-001.BMP', '/content/herle2005Format/train/Abnormal/149315229-149315291-001.BMP', '/content/herle2005Format/train/Abnormal/153915634-153915665-003.BMP', '/content/herle2005Format/train/Abnormal/154520056-154520096-001.BMP', '/content/herle2005Format/train/Abnormal/153827595-153827604-001.BMP', '/content/herle2005Format/train/Abnormal/149315671-149315740-003.BMP', '/content/herle2005Format/train/Abnormal/148719372-148719378-001.BMP', '/content/herle2005Format/train/Abnormal/153916569-153916586-001.BMP', '/content/herle2005Format/train/Abnormal/153698259-153698268-003.BMP', '/content/herle2005Format/train/Abnormal/149061666-149061726-002.BMP', '/content/herle2005Format/train/Abnormal/149057812-149057825-004.BMP']\n"
          ]
        }
      ],
      "source": [
        "#data augmentation\n",
        "#directories\n",
        "target_directory = \"/content/herle2005Format/train\"\n",
        "#create an instance of the class\n",
        "datasetda = DataAugmentation_Extension()\n",
        "datasetda.extend_dataset(target_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGboem54rzzG"
      },
      "source": [
        "**Feature Combination**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eanN7qKKlj-v",
        "outputId": "bc8372f6-bd72-4e86-a981-5437e33968ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8235 images belonging to 2 classes.\n",
            "Found 8235 images belonging to 2 classes.\n",
            "Found 184 images belonging to 2 classes.\n",
            "Found 184 images belonging to 2 classes.\n",
            "Found 184 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From <ipython-input-13-2d8f78356d3f>:86: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n",
            "Epoch 1/200\n",
            "258/258 - 1s - loss: 0.1519 - acc: 0.9477 - val_loss: 0.0500 - val_acc: 0.9837\n",
            "Epoch 2/200\n",
            "258/258 - 1s - loss: 0.1078 - acc: 0.9611 - val_loss: 0.0486 - val_acc: 0.9891\n",
            "Epoch 3/200\n",
            "258/258 - 1s - loss: 0.1074 - acc: 0.9620 - val_loss: 0.0695 - val_acc: 0.9783\n",
            "Epoch 4/200\n",
            "258/258 - 1s - loss: 0.1037 - acc: 0.9678 - val_loss: 0.0472 - val_acc: 0.9837\n",
            "Epoch 5/200\n",
            "258/258 - 1s - loss: 0.0965 - acc: 0.9679 - val_loss: 0.0570 - val_acc: 0.9837\n",
            "Epoch 6/200\n",
            "258/258 - 1s - loss: 0.1060 - acc: 0.9628 - val_loss: 0.0449 - val_acc: 0.9837\n",
            "Epoch 7/200\n",
            "258/258 - 1s - loss: 0.0916 - acc: 0.9702 - val_loss: 0.0586 - val_acc: 0.9783\n",
            "Epoch 8/200\n",
            "258/258 - 1s - loss: 0.0902 - acc: 0.9728 - val_loss: 0.0398 - val_acc: 0.9837\n",
            "Epoch 9/200\n",
            "258/258 - 1s - loss: 0.1025 - acc: 0.9685 - val_loss: 0.0588 - val_acc: 0.9837\n",
            "Epoch 10/200\n",
            "258/258 - 1s - loss: 0.0981 - acc: 0.9711 - val_loss: 0.0708 - val_acc: 0.9837\n",
            "Epoch 11/200\n",
            "258/258 - 1s - loss: 0.0973 - acc: 0.9675 - val_loss: 0.0535 - val_acc: 0.9837\n",
            "Epoch 12/200\n",
            "258/258 - 1s - loss: 0.0957 - acc: 0.9696 - val_loss: 0.0508 - val_acc: 0.9837\n",
            "Epoch 13/200\n",
            "258/258 - 1s - loss: 0.0970 - acc: 0.9693 - val_loss: 0.0747 - val_acc: 0.9837\n",
            "Epoch 14/200\n",
            "258/258 - 1s - loss: 0.1019 - acc: 0.9670 - val_loss: 0.0897 - val_acc: 0.9837\n",
            "Epoch 15/200\n",
            "258/258 - 1s - loss: 0.0967 - acc: 0.9688 - val_loss: 0.1003 - val_acc: 0.9783\n",
            "Epoch 16/200\n",
            "258/258 - 1s - loss: 0.1014 - acc: 0.9683 - val_loss: 0.0689 - val_acc: 0.9783\n",
            "Epoch 17/200\n",
            "258/258 - 1s - loss: 0.0965 - acc: 0.9700 - val_loss: 0.0692 - val_acc: 0.9783\n",
            "Epoch 18/200\n",
            "258/258 - 1s - loss: 0.0905 - acc: 0.9717 - val_loss: 0.0868 - val_acc: 0.9783\n",
            "Epoch 19/200\n",
            "258/258 - 1s - loss: 0.0900 - acc: 0.9706 - val_loss: 0.0739 - val_acc: 0.9837\n",
            "Epoch 20/200\n",
            "258/258 - 1s - loss: 0.1042 - acc: 0.9690 - val_loss: 0.0654 - val_acc: 0.9837\n",
            "Epoch 21/200\n",
            "258/258 - 1s - loss: 0.1000 - acc: 0.9709 - val_loss: 0.0700 - val_acc: 0.9837\n",
            "Epoch 22/200\n",
            "258/258 - 1s - loss: 0.0969 - acc: 0.9717 - val_loss: 0.0559 - val_acc: 0.9837\n",
            "Epoch 23/200\n",
            "258/258 - 1s - loss: 0.0918 - acc: 0.9728 - val_loss: 0.0737 - val_acc: 0.9837\n",
            "Epoch 24/200\n",
            "258/258 - 1s - loss: 0.0978 - acc: 0.9707 - val_loss: 0.0740 - val_acc: 0.9783\n",
            "Epoch 25/200\n",
            "258/258 - 1s - loss: 0.0954 - acc: 0.9713 - val_loss: 0.0741 - val_acc: 0.9837\n",
            "Epoch 26/200\n",
            "258/258 - 1s - loss: 0.1014 - acc: 0.9684 - val_loss: 0.0787 - val_acc: 0.9783\n",
            "Epoch 27/200\n",
            "258/258 - 1s - loss: 0.1008 - acc: 0.9709 - val_loss: 0.0778 - val_acc: 0.9783\n",
            "Epoch 28/200\n",
            "258/258 - 1s - loss: 0.0959 - acc: 0.9718 - val_loss: 0.0795 - val_acc: 0.9783\n",
            "Epoch 29/200\n",
            "258/258 - 1s - loss: 0.1035 - acc: 0.9689 - val_loss: 0.0816 - val_acc: 0.9837\n",
            "Epoch 30/200\n",
            "258/258 - 1s - loss: 0.0965 - acc: 0.9734 - val_loss: 0.0846 - val_acc: 0.9837\n",
            "Epoch 31/200\n",
            "258/258 - 1s - loss: 0.0979 - acc: 0.9704 - val_loss: 0.1039 - val_acc: 0.9783\n",
            "Epoch 32/200\n",
            "258/258 - 1s - loss: 0.1074 - acc: 0.9683 - val_loss: 0.0778 - val_acc: 0.9837\n",
            "Epoch 33/200\n",
            "258/258 - 1s - loss: 0.1119 - acc: 0.9678 - val_loss: 0.0672 - val_acc: 0.9837\n",
            "Epoch 34/200\n",
            "258/258 - 1s - loss: 0.0976 - acc: 0.9710 - val_loss: 0.0646 - val_acc: 0.9783\n",
            "Epoch 35/200\n",
            "258/258 - 1s - loss: 0.1121 - acc: 0.9692 - val_loss: 0.0540 - val_acc: 0.9783\n",
            "Epoch 36/200\n",
            "258/258 - 1s - loss: 0.0923 - acc: 0.9721 - val_loss: 0.0591 - val_acc: 0.9837\n",
            "Epoch 37/200\n",
            "258/258 - 1s - loss: 0.0894 - acc: 0.9696 - val_loss: 0.0716 - val_acc: 0.9783\n",
            "Epoch 38/200\n",
            "258/258 - 1s - loss: 0.1029 - acc: 0.9707 - val_loss: 0.0747 - val_acc: 0.9837\n",
            "Epoch 39/200\n",
            "258/258 - 1s - loss: 0.0961 - acc: 0.9702 - val_loss: 0.0748 - val_acc: 0.9783\n",
            "Epoch 40/200\n",
            "258/258 - 1s - loss: 0.0990 - acc: 0.9712 - val_loss: 0.0617 - val_acc: 0.9783\n",
            "Epoch 41/200\n",
            "258/258 - 1s - loss: 0.1014 - acc: 0.9721 - val_loss: 0.0735 - val_acc: 0.9783\n",
            "Epoch 42/200\n",
            "258/258 - 1s - loss: 0.0878 - acc: 0.9736 - val_loss: 0.0645 - val_acc: 0.9837\n",
            "Epoch 43/200\n",
            "258/258 - 1s - loss: 0.0917 - acc: 0.9735 - val_loss: 0.0826 - val_acc: 0.9837\n",
            "Epoch 44/200\n",
            "258/258 - 1s - loss: 0.0926 - acc: 0.9723 - val_loss: 0.0938 - val_acc: 0.9837\n",
            "Epoch 45/200\n",
            "258/258 - 1s - loss: 0.0868 - acc: 0.9719 - val_loss: 0.1000 - val_acc: 0.9837\n",
            "Epoch 46/200\n",
            "258/258 - 1s - loss: 0.1035 - acc: 0.9716 - val_loss: 0.0827 - val_acc: 0.9837\n",
            "Epoch 47/200\n",
            "258/258 - 1s - loss: 0.0951 - acc: 0.9718 - val_loss: 0.0888 - val_acc: 0.9837\n",
            "Epoch 48/200\n",
            "258/258 - 1s - loss: 0.1158 - acc: 0.9675 - val_loss: 0.0810 - val_acc: 0.9837\n",
            "Epoch 49/200\n",
            "258/258 - 1s - loss: 0.0885 - acc: 0.9722 - val_loss: 0.0897 - val_acc: 0.9783\n",
            "Epoch 50/200\n",
            "258/258 - 1s - loss: 0.0961 - acc: 0.9729 - val_loss: 0.0872 - val_acc: 0.9837\n",
            "Epoch 51/200\n",
            "258/258 - 1s - loss: 0.0969 - acc: 0.9735 - val_loss: 0.0693 - val_acc: 0.9837\n",
            "Epoch 52/200\n",
            "258/258 - 1s - loss: 0.0939 - acc: 0.9746 - val_loss: 0.0779 - val_acc: 0.9837\n",
            "Epoch 53/200\n",
            "258/258 - 1s - loss: 0.0964 - acc: 0.9728 - val_loss: 0.0663 - val_acc: 0.9837\n",
            "Epoch 54/200\n",
            "258/258 - 1s - loss: 0.0947 - acc: 0.9722 - val_loss: 0.0886 - val_acc: 0.9783\n",
            "Epoch 55/200\n",
            "258/258 - 1s - loss: 0.1049 - acc: 0.9726 - val_loss: 0.0805 - val_acc: 0.9837\n",
            "Epoch 56/200\n",
            "258/258 - 1s - loss: 0.0876 - acc: 0.9745 - val_loss: 0.0885 - val_acc: 0.9837\n",
            "Epoch 57/200\n",
            "258/258 - 1s - loss: 0.0837 - acc: 0.9736 - val_loss: 0.0979 - val_acc: 0.9783\n",
            "Epoch 58/200\n",
            "258/258 - 1s - loss: 0.1106 - acc: 0.9693 - val_loss: 0.1001 - val_acc: 0.9674\n",
            "Epoch 59/200\n",
            "258/258 - 1s - loss: 0.0989 - acc: 0.9696 - val_loss: 0.1017 - val_acc: 0.9783\n",
            "Epoch 60/200\n",
            "258/258 - 1s - loss: 0.0934 - acc: 0.9723 - val_loss: 0.0807 - val_acc: 0.9837\n",
            "Epoch 61/200\n",
            "258/258 - 1s - loss: 0.0860 - acc: 0.9755 - val_loss: 0.0674 - val_acc: 0.9783\n",
            "Epoch 62/200\n",
            "258/258 - 1s - loss: 0.1062 - acc: 0.9705 - val_loss: 0.0642 - val_acc: 0.9783\n",
            "Epoch 63/200\n",
            "258/258 - 1s - loss: 0.1002 - acc: 0.9699 - val_loss: 0.0817 - val_acc: 0.9783\n",
            "Epoch 64/200\n",
            "258/258 - 1s - loss: 0.0960 - acc: 0.9736 - val_loss: 0.0737 - val_acc: 0.9783\n",
            "Epoch 65/200\n",
            "258/258 - 1s - loss: 0.0986 - acc: 0.9706 - val_loss: 0.0631 - val_acc: 0.9783\n",
            "Epoch 66/200\n",
            "258/258 - 1s - loss: 0.1000 - acc: 0.9732 - val_loss: 0.1017 - val_acc: 0.9728\n",
            "Epoch 67/200\n",
            "258/258 - 1s - loss: 0.0920 - acc: 0.9728 - val_loss: 0.0898 - val_acc: 0.9783\n",
            "Epoch 68/200\n",
            "258/258 - 1s - loss: 0.0882 - acc: 0.9733 - val_loss: 0.0739 - val_acc: 0.9783\n",
            "Epoch 69/200\n",
            "258/258 - 1s - loss: 0.0907 - acc: 0.9741 - val_loss: 0.0792 - val_acc: 0.9837\n",
            "Epoch 70/200\n",
            "258/258 - 1s - loss: 0.0905 - acc: 0.9741 - val_loss: 0.0857 - val_acc: 0.9728\n",
            "Epoch 71/200\n",
            "258/258 - 1s - loss: 0.1019 - acc: 0.9716 - val_loss: 0.0736 - val_acc: 0.9783\n",
            "Epoch 72/200\n",
            "258/258 - 1s - loss: 0.0962 - acc: 0.9722 - val_loss: 0.0873 - val_acc: 0.9837\n",
            "Epoch 73/200\n",
            "258/258 - 1s - loss: 0.0992 - acc: 0.9717 - val_loss: 0.0679 - val_acc: 0.9837\n",
            "Epoch 74/200\n",
            "258/258 - 1s - loss: 0.0876 - acc: 0.9746 - val_loss: 0.0732 - val_acc: 0.9837\n",
            "Epoch 75/200\n",
            "258/258 - 1s - loss: 0.0971 - acc: 0.9738 - val_loss: 0.0901 - val_acc: 0.9837\n",
            "Epoch 76/200\n",
            "258/258 - 1s - loss: 0.0909 - acc: 0.9724 - val_loss: 0.0784 - val_acc: 0.9837\n",
            "Epoch 77/200\n",
            "258/258 - 1s - loss: 0.0826 - acc: 0.9741 - val_loss: 0.0699 - val_acc: 0.9783\n",
            "Epoch 78/200\n",
            "258/258 - 1s - loss: 0.0809 - acc: 0.9751 - val_loss: 0.0902 - val_acc: 0.9783\n",
            "Epoch 79/200\n",
            "258/258 - 1s - loss: 0.0925 - acc: 0.9734 - val_loss: 0.1056 - val_acc: 0.9728\n",
            "Epoch 80/200\n",
            "258/258 - 1s - loss: 0.0923 - acc: 0.9733 - val_loss: 0.2113 - val_acc: 0.9783\n",
            "Epoch 81/200\n",
            "258/258 - 1s - loss: 0.0895 - acc: 0.9735 - val_loss: 0.2199 - val_acc: 0.9783\n",
            "Epoch 82/200\n",
            "258/258 - 1s - loss: 0.1036 - acc: 0.9717 - val_loss: 0.0640 - val_acc: 0.9837\n",
            "Epoch 83/200\n",
            "258/258 - 1s - loss: 0.0823 - acc: 0.9755 - val_loss: 0.0596 - val_acc: 0.9783\n",
            "Epoch 84/200\n",
            "258/258 - 1s - loss: 0.0895 - acc: 0.9767 - val_loss: 0.2050 - val_acc: 0.9837\n",
            "Epoch 85/200\n",
            "258/258 - 1s - loss: 0.0962 - acc: 0.9722 - val_loss: 0.1911 - val_acc: 0.9783\n",
            "Epoch 86/200\n",
            "258/258 - 1s - loss: 0.0946 - acc: 0.9723 - val_loss: 0.0678 - val_acc: 0.9891\n",
            "Epoch 87/200\n",
            "258/258 - 1s - loss: 0.0898 - acc: 0.9723 - val_loss: 0.0534 - val_acc: 0.9837\n",
            "Epoch 88/200\n",
            "258/258 - 1s - loss: 0.0896 - acc: 0.9724 - val_loss: 0.0662 - val_acc: 0.9783\n",
            "Epoch 89/200\n",
            "258/258 - 1s - loss: 0.0983 - acc: 0.9712 - val_loss: 0.1523 - val_acc: 0.9783\n",
            "Epoch 90/200\n",
            "258/258 - 1s - loss: 0.1073 - acc: 0.9707 - val_loss: 0.0635 - val_acc: 0.9891\n",
            "Epoch 91/200\n",
            "258/258 - 1s - loss: 0.0923 - acc: 0.9705 - val_loss: 0.0625 - val_acc: 0.9837\n",
            "Epoch 92/200\n",
            "258/258 - 1s - loss: 0.0919 - acc: 0.9700 - val_loss: 0.0627 - val_acc: 0.9837\n",
            "Epoch 93/200\n",
            "258/258 - 1s - loss: 0.0863 - acc: 0.9730 - val_loss: 0.0640 - val_acc: 0.9837\n",
            "Epoch 94/200\n",
            "258/258 - 1s - loss: 0.0940 - acc: 0.9722 - val_loss: 0.0748 - val_acc: 0.9837\n",
            "Epoch 95/200\n",
            "258/258 - 1s - loss: 0.0970 - acc: 0.9711 - val_loss: 0.0811 - val_acc: 0.9837\n",
            "Epoch 96/200\n",
            "258/258 - 1s - loss: 0.0843 - acc: 0.9733 - val_loss: 0.0729 - val_acc: 0.9837\n",
            "Epoch 97/200\n",
            "258/258 - 1s - loss: 0.0905 - acc: 0.9732 - val_loss: 0.0878 - val_acc: 0.9837\n",
            "Epoch 98/200\n",
            "258/258 - 1s - loss: 0.0986 - acc: 0.9707 - val_loss: 0.0709 - val_acc: 0.9837\n",
            "Epoch 99/200\n",
            "258/258 - 1s - loss: 0.0888 - acc: 0.9730 - val_loss: 0.0841 - val_acc: 0.9783\n",
            "Epoch 100/200\n",
            "258/258 - 1s - loss: 0.0915 - acc: 0.9723 - val_loss: 0.0843 - val_acc: 0.9783\n",
            "Epoch 101/200\n",
            "258/258 - 1s - loss: 0.0881 - acc: 0.9730 - val_loss: 0.0887 - val_acc: 0.9837\n",
            "Epoch 102/200\n",
            "258/258 - 1s - loss: 0.0851 - acc: 0.9729 - val_loss: 0.0972 - val_acc: 0.9783\n",
            "Epoch 103/200\n",
            "258/258 - 1s - loss: 0.0909 - acc: 0.9728 - val_loss: 0.0945 - val_acc: 0.9837\n",
            "Epoch 104/200\n",
            "258/258 - 1s - loss: 0.0909 - acc: 0.9713 - val_loss: 0.0821 - val_acc: 0.9783\n",
            "Epoch 105/200\n",
            "258/258 - 1s - loss: 0.1011 - acc: 0.9704 - val_loss: 0.0740 - val_acc: 0.9837\n",
            "Epoch 106/200\n",
            "258/258 - 1s - loss: 0.0982 - acc: 0.9710 - val_loss: 0.0845 - val_acc: 0.9837\n",
            "Epoch 107/200\n",
            "258/258 - 1s - loss: 0.0931 - acc: 0.9724 - val_loss: 0.0734 - val_acc: 0.9837\n",
            "Epoch 108/200\n",
            "258/258 - 1s - loss: 0.0799 - acc: 0.9752 - val_loss: 0.0640 - val_acc: 0.9837\n",
            "Epoch 109/200\n",
            "258/258 - 1s - loss: 0.0886 - acc: 0.9741 - val_loss: 0.0845 - val_acc: 0.9783\n",
            "Epoch 110/200\n",
            "258/258 - 1s - loss: 0.0928 - acc: 0.9716 - val_loss: 0.0688 - val_acc: 0.9783\n",
            "Epoch 111/200\n",
            "258/258 - 1s - loss: 0.0869 - acc: 0.9750 - val_loss: 0.0702 - val_acc: 0.9837\n",
            "Epoch 112/200\n",
            "258/258 - 1s - loss: 0.0910 - acc: 0.9721 - val_loss: 0.0898 - val_acc: 0.9728\n",
            "Epoch 113/200\n",
            "258/258 - 1s - loss: 0.0815 - acc: 0.9751 - val_loss: 0.0855 - val_acc: 0.9837\n",
            "Epoch 114/200\n",
            "258/258 - 1s - loss: 0.0867 - acc: 0.9753 - val_loss: 0.0815 - val_acc: 0.9837\n",
            "Epoch 115/200\n",
            "258/258 - 1s - loss: 0.0858 - acc: 0.9753 - val_loss: 0.1484 - val_acc: 0.9674\n",
            "Epoch 116/200\n",
            "258/258 - 1s - loss: 0.0861 - acc: 0.9728 - val_loss: 0.1018 - val_acc: 0.9783\n",
            "Epoch 117/200\n",
            "258/258 - 1s - loss: 0.0947 - acc: 0.9713 - val_loss: 0.0977 - val_acc: 0.9783\n",
            "Epoch 118/200\n",
            "258/258 - 1s - loss: 0.0911 - acc: 0.9727 - val_loss: 0.0813 - val_acc: 0.9837\n",
            "Epoch 119/200\n",
            "258/258 - 1s - loss: 0.0904 - acc: 0.9734 - val_loss: 0.0788 - val_acc: 0.9837\n",
            "Epoch 120/200\n",
            "258/258 - 1s - loss: 0.0935 - acc: 0.9717 - val_loss: 0.0772 - val_acc: 0.9837\n",
            "Epoch 121/200\n",
            "258/258 - 1s - loss: 0.0883 - acc: 0.9740 - val_loss: 0.0838 - val_acc: 0.9837\n",
            "Epoch 122/200\n",
            "258/258 - 1s - loss: 0.0987 - acc: 0.9717 - val_loss: 0.0685 - val_acc: 0.9837\n",
            "Epoch 123/200\n",
            "258/258 - 1s - loss: 0.0786 - acc: 0.9739 - val_loss: 0.0757 - val_acc: 0.9837\n",
            "Epoch 124/200\n",
            "258/258 - 1s - loss: 0.0825 - acc: 0.9746 - val_loss: 0.0688 - val_acc: 0.9837\n",
            "Epoch 125/200\n",
            "258/258 - 1s - loss: 0.0900 - acc: 0.9727 - val_loss: 0.0656 - val_acc: 0.9837\n",
            "Epoch 126/200\n",
            "258/258 - 1s - loss: 0.0954 - acc: 0.9734 - val_loss: 0.0800 - val_acc: 0.9837\n",
            "Epoch 127/200\n",
            "258/258 - 1s - loss: 0.0823 - acc: 0.9741 - val_loss: 0.0714 - val_acc: 0.9837\n",
            "Epoch 128/200\n",
            "258/258 - 1s - loss: 0.0857 - acc: 0.9739 - val_loss: 0.0639 - val_acc: 0.9837\n",
            "Epoch 129/200\n",
            "258/258 - 1s - loss: 0.0834 - acc: 0.9715 - val_loss: 0.0693 - val_acc: 0.9837\n",
            "Epoch 130/200\n",
            "258/258 - 1s - loss: 0.0844 - acc: 0.9767 - val_loss: 0.0792 - val_acc: 0.9891\n",
            "Epoch 131/200\n",
            "258/258 - 1s - loss: 0.0772 - acc: 0.9769 - val_loss: 0.0826 - val_acc: 0.9783\n",
            "Epoch 132/200\n",
            "258/258 - 1s - loss: 0.0939 - acc: 0.9721 - val_loss: 0.0766 - val_acc: 0.9891\n",
            "Epoch 133/200\n",
            "258/258 - 1s - loss: 0.0846 - acc: 0.9728 - val_loss: 0.0626 - val_acc: 0.9837\n",
            "Epoch 134/200\n",
            "258/258 - 1s - loss: 0.0909 - acc: 0.9738 - val_loss: 0.0687 - val_acc: 0.9837\n",
            "Epoch 135/200\n",
            "258/258 - 1s - loss: 0.0853 - acc: 0.9724 - val_loss: 0.0692 - val_acc: 0.9837\n",
            "Epoch 136/200\n",
            "258/258 - 1s - loss: 0.0808 - acc: 0.9756 - val_loss: 0.0675 - val_acc: 0.9783\n",
            "Epoch 137/200\n",
            "258/258 - 1s - loss: 0.0862 - acc: 0.9736 - val_loss: 0.0507 - val_acc: 0.9837\n",
            "Epoch 138/200\n",
            "258/258 - 1s - loss: 0.0842 - acc: 0.9751 - val_loss: 0.0512 - val_acc: 0.9837\n",
            "Epoch 139/200\n",
            "258/258 - 1s - loss: 0.0808 - acc: 0.9744 - val_loss: 0.0526 - val_acc: 0.9837\n",
            "Epoch 140/200\n",
            "258/258 - 1s - loss: 0.0803 - acc: 0.9750 - val_loss: 0.0524 - val_acc: 0.9837\n",
            "Epoch 141/200\n",
            "258/258 - 1s - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0553 - val_acc: 0.9783\n",
            "Epoch 142/200\n",
            "258/258 - 1s - loss: 0.0883 - acc: 0.9735 - val_loss: 0.0609 - val_acc: 0.9891\n",
            "Epoch 143/200\n",
            "258/258 - 1s - loss: 0.0914 - acc: 0.9712 - val_loss: 0.0764 - val_acc: 0.9728\n",
            "Epoch 144/200\n",
            "258/258 - 1s - loss: 0.0865 - acc: 0.9732 - val_loss: 0.0693 - val_acc: 0.9837\n",
            "Epoch 145/200\n",
            "258/258 - 1s - loss: 0.0868 - acc: 0.9744 - val_loss: 0.0581 - val_acc: 0.9837\n",
            "Epoch 146/200\n",
            "258/258 - 1s - loss: 0.0900 - acc: 0.9738 - val_loss: 0.0622 - val_acc: 0.9837\n",
            "Epoch 147/200\n",
            "258/258 - 1s - loss: 0.0822 - acc: 0.9739 - val_loss: 0.0589 - val_acc: 0.9837\n",
            "Epoch 148/200\n",
            "258/258 - 1s - loss: 0.0928 - acc: 0.9710 - val_loss: 0.0727 - val_acc: 0.9783\n",
            "Epoch 149/200\n",
            "258/258 - 1s - loss: 0.0882 - acc: 0.9718 - val_loss: 0.0796 - val_acc: 0.9783\n",
            "Epoch 150/200\n",
            "258/258 - 1s - loss: 0.0863 - acc: 0.9738 - val_loss: 0.0690 - val_acc: 0.9837\n",
            "Epoch 151/200\n",
            "258/258 - 1s - loss: 0.0829 - acc: 0.9740 - val_loss: 0.0632 - val_acc: 0.9837\n",
            "Epoch 152/200\n",
            "258/258 - 1s - loss: 0.0831 - acc: 0.9736 - val_loss: 0.0803 - val_acc: 0.9837\n",
            "Epoch 153/200\n",
            "258/258 - 1s - loss: 0.0892 - acc: 0.9705 - val_loss: 0.0940 - val_acc: 0.9728\n",
            "Epoch 154/200\n",
            "258/258 - 1s - loss: 0.0717 - acc: 0.9752 - val_loss: 0.0750 - val_acc: 0.9837\n",
            "Epoch 155/200\n",
            "258/258 - 1s - loss: 0.0743 - acc: 0.9747 - val_loss: 0.0729 - val_acc: 0.9837\n",
            "Epoch 156/200\n",
            "258/258 - 1s - loss: 0.0741 - acc: 0.9764 - val_loss: 0.0705 - val_acc: 0.9837\n",
            "Epoch 157/200\n",
            "258/258 - 1s - loss: 0.0823 - acc: 0.9745 - val_loss: 0.0712 - val_acc: 0.9837\n",
            "Epoch 158/200\n",
            "258/258 - 1s - loss: 0.0788 - acc: 0.9745 - val_loss: 0.0847 - val_acc: 0.9837\n",
            "Epoch 159/200\n",
            "258/258 - 1s - loss: 0.0754 - acc: 0.9751 - val_loss: 0.0720 - val_acc: 0.9837\n",
            "Epoch 160/200\n",
            "258/258 - 1s - loss: 0.0829 - acc: 0.9721 - val_loss: 0.0825 - val_acc: 0.9837\n",
            "Epoch 161/200\n",
            "258/258 - 1s - loss: 0.0880 - acc: 0.9724 - val_loss: 0.1283 - val_acc: 0.9728\n",
            "Epoch 162/200\n",
            "258/258 - 1s - loss: 0.0793 - acc: 0.9741 - val_loss: 0.0814 - val_acc: 0.9728\n",
            "Epoch 163/200\n",
            "258/258 - 1s - loss: 0.0871 - acc: 0.9729 - val_loss: 0.1098 - val_acc: 0.9674\n",
            "Epoch 164/200\n",
            "258/258 - 1s - loss: 0.0930 - acc: 0.9709 - val_loss: 0.0850 - val_acc: 0.9783\n",
            "Epoch 165/200\n",
            "258/258 - 1s - loss: 0.0816 - acc: 0.9743 - val_loss: 0.0747 - val_acc: 0.9837\n",
            "Epoch 166/200\n",
            "258/258 - 1s - loss: 0.0776 - acc: 0.9750 - val_loss: 0.1259 - val_acc: 0.9783\n",
            "Epoch 167/200\n",
            "258/258 - 1s - loss: 0.0800 - acc: 0.9732 - val_loss: 0.1212 - val_acc: 0.9783\n",
            "Epoch 168/200\n",
            "258/258 - 1s - loss: 0.0790 - acc: 0.9752 - val_loss: 0.0882 - val_acc: 0.9783\n",
            "Epoch 169/200\n",
            "258/258 - 1s - loss: 0.0824 - acc: 0.9730 - val_loss: 0.2168 - val_acc: 0.9783\n",
            "Epoch 170/200\n",
            "258/258 - 1s - loss: 0.0721 - acc: 0.9764 - val_loss: 0.3781 - val_acc: 0.9783\n",
            "Epoch 171/200\n",
            "258/258 - 1s - loss: 0.0768 - acc: 0.9745 - val_loss: 0.4570 - val_acc: 0.9783\n",
            "Epoch 172/200\n",
            "258/258 - 1s - loss: 0.0760 - acc: 0.9763 - val_loss: 0.0857 - val_acc: 0.9783\n",
            "Epoch 173/200\n",
            "258/258 - 1s - loss: 0.0837 - acc: 0.9722 - val_loss: 0.4016 - val_acc: 0.9783\n",
            "Epoch 174/200\n",
            "258/258 - 1s - loss: 0.0856 - acc: 0.9729 - val_loss: 0.3548 - val_acc: 0.9783\n",
            "Epoch 175/200\n",
            "258/258 - 1s - loss: 0.0808 - acc: 0.9751 - val_loss: 0.1437 - val_acc: 0.9728\n",
            "Epoch 176/200\n",
            "258/258 - 1s - loss: 0.0768 - acc: 0.9753 - val_loss: 0.2115 - val_acc: 0.9620\n",
            "Epoch 177/200\n",
            "258/258 - 1s - loss: 0.0874 - acc: 0.9741 - val_loss: 0.1139 - val_acc: 0.9783\n",
            "Epoch 178/200\n",
            "258/258 - 1s - loss: 0.0777 - acc: 0.9743 - val_loss: 0.2284 - val_acc: 0.9783\n",
            "Epoch 179/200\n",
            "258/258 - 1s - loss: 0.0726 - acc: 0.9772 - val_loss: 0.1926 - val_acc: 0.9728\n",
            "Epoch 180/200\n",
            "258/258 - 1s - loss: 0.0850 - acc: 0.9728 - val_loss: 0.3239 - val_acc: 0.9783\n",
            "Epoch 181/200\n",
            "258/258 - 1s - loss: 0.0691 - acc: 0.9768 - val_loss: 0.1345 - val_acc: 0.9783\n",
            "Epoch 182/200\n",
            "258/258 - 1s - loss: 0.0876 - acc: 0.9728 - val_loss: 0.2520 - val_acc: 0.9783\n",
            "Epoch 183/200\n",
            "258/258 - 1s - loss: 0.0818 - acc: 0.9747 - val_loss: 0.4179 - val_acc: 0.9783\n",
            "Epoch 184/200\n",
            "258/258 - 1s - loss: 0.0719 - acc: 0.9755 - val_loss: 0.2556 - val_acc: 0.9728\n",
            "Epoch 185/200\n",
            "258/258 - 1s - loss: 0.0872 - acc: 0.9694 - val_loss: 0.4273 - val_acc: 0.9728\n",
            "Epoch 186/200\n",
            "258/258 - 1s - loss: 0.0720 - acc: 0.9752 - val_loss: 0.1286 - val_acc: 0.9728\n",
            "Epoch 187/200\n",
            "258/258 - 1s - loss: 0.0755 - acc: 0.9751 - val_loss: 0.3285 - val_acc: 0.9728\n",
            "Epoch 188/200\n",
            "258/258 - 1s - loss: 0.0796 - acc: 0.9740 - val_loss: 0.1735 - val_acc: 0.9728\n",
            "Epoch 189/200\n",
            "258/258 - 1s - loss: 0.0736 - acc: 0.9761 - val_loss: 0.0926 - val_acc: 0.9783\n",
            "Epoch 190/200\n",
            "258/258 - 1s - loss: 0.0862 - acc: 0.9719 - val_loss: 0.0851 - val_acc: 0.9674\n",
            "Epoch 191/200\n",
            "258/258 - 1s - loss: 0.0789 - acc: 0.9722 - val_loss: 0.2117 - val_acc: 0.9783\n",
            "Epoch 192/200\n",
            "258/258 - 1s - loss: 0.0749 - acc: 0.9751 - val_loss: 0.1152 - val_acc: 0.9728\n",
            "Epoch 193/200\n",
            "258/258 - 1s - loss: 0.0826 - acc: 0.9712 - val_loss: 0.1074 - val_acc: 0.9783\n",
            "Epoch 194/200\n",
            "258/258 - 1s - loss: 0.0714 - acc: 0.9767 - val_loss: 0.0590 - val_acc: 0.9837\n",
            "Epoch 195/200\n",
            "258/258 - 1s - loss: 0.0726 - acc: 0.9767 - val_loss: 0.1290 - val_acc: 0.9728\n",
            "Epoch 196/200\n",
            "258/258 - 1s - loss: 0.0885 - acc: 0.9716 - val_loss: 0.1325 - val_acc: 0.9728\n",
            "Epoch 197/200\n",
            "258/258 - 1s - loss: 0.0846 - acc: 0.9732 - val_loss: 0.0737 - val_acc: 0.9783\n",
            "Epoch 198/200\n",
            "258/258 - 1s - loss: 0.0801 - acc: 0.9747 - val_loss: 0.0772 - val_acc: 0.9783\n",
            "Epoch 199/200\n",
            "258/258 - 1s - loss: 0.0898 - acc: 0.9716 - val_loss: 0.0685 - val_acc: 0.9837\n",
            "Epoch 200/200\n",
            "258/258 - 1s - loss: 0.0793 - acc: 0.9758 - val_loss: 0.0705 - val_acc: 0.9783\n",
            "0.9619565217391305\n",
            "[[132   3]\n",
            " [  4  45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       135\n",
            "           1       0.94      0.92      0.93        49\n",
            "\n",
            "    accuracy                           0.96       184\n",
            "   macro avg       0.95      0.95      0.95       184\n",
            "weighted avg       0.96      0.96      0.96       184\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "\"\"\"LOAD DATA\"\"\"\n",
        "# path to folder with data\n",
        "path = \"/content/herle2005Format/\"\n",
        "# expected data structure inside folder: train, test, val. in each folder: one folder for each class,\n",
        "# comprising its respective slide images.\n",
        "\n",
        "\n",
        "# specify image data generator with data augmentation (train_datagen) resp. without (no_DA_IDG)\n",
        "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
        "                                    rotation_range = 5, fill_mode=\"nearest\",\n",
        "                                    zoom_range=[1/1.0, 1/1.0], width_shift_range=0.0, height_shift_range=0.0, # occasionally out of range\n",
        "                                    horizontal_flip = True, vertical_flip=True,\n",
        "                                    brightness_range=[0.5, 1.3], channel_shift_range=20)\n",
        "\n",
        "no_DA_IDG = ImageDataGenerator()\n",
        "\n",
        "# in training set: use data augmentation image data generator, for validation and test: no data augmentation.\n",
        "training_set = train_datagen.flow_from_directory(path+\"train/\",\n",
        "                                                target_size=(224, 224), # typical imagenet dimensions\n",
        "                                                color_mode='rgb',\n",
        "                                                batch_size=32,\n",
        "                                                class_mode='categorical', shuffle=True)\n",
        "\n",
        "training_set_V2 =  no_DA_IDG.flow_from_directory(path+\"train/\", ### TO USE FOR FEATURE EXTRACTION\n",
        "                                                target_size=(224, 224), # typical imagenet dimensions\n",
        "                                                color_mode='rgb',\n",
        "                                                batch_size=1,\n",
        "                                                class_mode='categorical', shuffle=False)\n",
        "\n",
        "validation_set = no_DA_IDG.flow_from_directory(path+\"val/\",\n",
        "                                                target_size=(224, 224),\n",
        "                                                color_mode='rgb',\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True)\n",
        "\n",
        "validation_set_V2 = no_DA_IDG.flow_from_directory(path+\"val/\",\n",
        "                                                target_size=(224, 224),\n",
        "                                                color_mode='rgb',\n",
        "                                                batch_size=1,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=False)\n",
        "\n",
        "test_set_V2 = no_DA_IDG.flow_from_directory(path+\"test/\",\n",
        "                                                target_size=(224, 224),\n",
        "                                                color_mode='rgb',\n",
        "                                                batch_size=1,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=False)\n",
        "\n",
        "###############################################################################################\n",
        "\"\"\"CREATE MODELS\"\"\"\n",
        "from keras.models import Sequential, load_model\n",
        "model_vgg = load_model('model_vgg16_herlev_binary.h5') \n",
        "model_xcep = load_model('model_xcep_herlev_binary.h5')\n",
        "model_vgg19 = load_model('model_vgg19_herlev_binary.h5')\n",
        "model_res50 = load_model('model_R50_T2_herlev_binary.h5')\n",
        "\n",
        "\"\"\"LOADING WEIGHTS FROM PREVIOUSLY TRAINED MODELS\"\"\"\n",
        "model_xcep.load_weights(\"K_xcep_T2_herlev_binary.h5\")\n",
        "model_vgg.load_weights(\"K_VGG16_T2_herlev_binary.h5\")\n",
        "model_res50.load_weights(\"K_R50_T2_herlev_binary.h5\")\n",
        "model_vgg19.load_weights(\"K_VGG19_T2_herlev_binary.h5\")\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"MODEL COMBINATION\"\"\"\n",
        "# creating the model extracting features from the last layer before the softmax layer.\n",
        "vgg_extractor = Model(inputs=model_vgg.input, outputs=model_vgg.get_layer(\"dense_1024\").output)\n",
        "xcep_extractor = Model(inputs=model_xcep.input, outputs=model_xcep.get_layer(\"dense_1024\").output)\n",
        "vgg19_extractor = Model(inputs=model_vgg19.input, outputs=model_vgg19.get_layer(\"dense_1024\").output)\n",
        "r50_extractor = Model(inputs=model_res50.input, outputs=model_res50.get_layer(\"dense_1024\").output)\n",
        "\n",
        "\n",
        "y_train = to_categorical(training_set_V2.classes)\n",
        "X_train_m1 = vgg_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
        "X_train_m2 = xcep_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
        "X_train_m3 = vgg19_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
        "X_train_m4 = r50_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
        "X_train = np.concatenate([X_train_m1, X_train_m2, X_train_m3, X_train_m4], axis=1)\n",
        "\n",
        "y_val = to_categorical(validation_set_V2.classes)\n",
        "X_val_m1 = vgg_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
        "X_val_m2 = xcep_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
        "X_val_m3 = vgg19_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
        "X_val_m4 = r50_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
        "X_val = np.concatenate([X_val_m1, X_val_m2, X_val_m3, X_val_m4], axis=1)\n",
        "\n",
        "y_test = to_categorical(test_set_V2.classes)\n",
        "X_test_m1 = vgg_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
        "X_test_m2 = xcep_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
        "X_test_m3 = vgg19_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
        "X_test_m4 = r50_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
        "X_test = np.concatenate([X_test_m1, X_test_m2, X_test_m3, X_test_m4], axis=1)\n",
        "\n",
        "\n",
        "\"\"\"TRAIN & TEST FEATURE EXTRACTION MODEL\"\"\"\n",
        "# the feature arrays are read into a sequential model directly connecting them to the softmax layer, with\n",
        "# some dropout and batch normalization in between.\n",
        "\n",
        "np.random.seed(668)\n",
        "\n",
        "opt = Adam(learning_rate=1e-3)\n",
        "model = Sequential()\n",
        "model.add(Dropout(0.5, input_shape=(4096,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation=\"softmax\"))\n",
        "model1=model\n",
        "model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "\n",
        "epochs = 200\n",
        "history1=model1.fit(X_train, y_train, batch_size=32, epochs=epochs, verbose=2, shuffle=True, validation_data=(X_val, y_val))\n",
        "\n",
        "\"\"\"EVALUATE MODEL ON TEST DATA\"\"\"\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "pred = np.argmax(model1.predict(X_test), axis=1)\n",
        "model1.save('model_binary_vgg16_vgg19_Res50_xception_herlev7class.h5')\n",
        "print(accuracy_score(y_test, pred))\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tripple_feature_combination_on_herlev_binary_class_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
